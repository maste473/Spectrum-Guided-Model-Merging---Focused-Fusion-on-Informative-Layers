{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Spectrum-Guided Model Merging: ResNet18 on FashionMNIST and KMNIST"
      ],
      "metadata": {
        "id": "p07ku_f4UxZC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9SXj6cldTpWT"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# IMPORT\n",
        "# ============================================================\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "\n",
        "from torchvision.models import ResNet18_Weights\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# ============================================================\n",
        "# DATASET DIVERSO PER TASK\n",
        "# ============================================================\n",
        "def get_datasets(batch_size=128):\n",
        "    transform_gray_to_rgb = transforms.Compose([\n",
        "        transforms.Resize(32),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Lambda(lambda x: x.repeat(3,1,1))\n",
        "    ])\n",
        "\n",
        "    # Task C: FashionMNIST\n",
        "    trainC = torchvision.datasets.FashionMNIST(root=\"./data\", train=True, download=True, transform=transform_gray_to_rgb)\n",
        "    testC  = torchvision.datasets.FashionMNIST(root=\"./data\", train=False, download=True, transform=transform_gray_to_rgb)\n",
        "    loaderC_train = torch.utils.data.DataLoader(trainC, batch_size=batch_size, shuffle=True)\n",
        "    loaderC_test  = torch.utils.data.DataLoader(testC, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # Task D: KMNIST\n",
        "    trainD = torchvision.datasets.KMNIST(root=\"./data\", train=True, download=True, transform=transform_gray_to_rgb)\n",
        "    testD  = torchvision.datasets.KMNIST(root=\"./data\", train=False, download=True, transform=transform_gray_to_rgb)\n",
        "    loaderD_train = torch.utils.data.DataLoader(trainD, batch_size=batch_size, shuffle=True)\n",
        "    loaderD_test  = torch.utils.data.DataLoader(testD, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    return loaderC_train, loaderC_test, loaderD_train, loaderD_test\n",
        "\n",
        "# ============================================================\n",
        "# MODEL\n",
        "# ============================================================\n",
        "def get_model():\n",
        "    model = torchvision.models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
        "    model.fc = nn.Linear(512, 10)\n",
        "    return model.to(device)\n",
        "\n",
        "# ============================================================\n",
        "# FINETUNING\n",
        "# ============================================================\n",
        "def finetune(model, loader, epochs=5, lr=1e-3):\n",
        "    model.train()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    for _ in range(epochs):\n",
        "        for x, y in loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            out = model(x)\n",
        "            loss = criterion(out, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "    return model\n",
        "\n",
        "# ============================================================\n",
        "# SPECTRUM SNR\n",
        "# ============================================================\n",
        "def compute_snr(weight):\n",
        "    W = weight.detach().cpu().numpy()\n",
        "    if W.ndim > 2:\n",
        "        W = W.reshape(W.shape[0], -1)\n",
        "    C = (W @ W.T) / W.shape[1]\n",
        "    eigvals = np.linalg.eigvalsh(C)\n",
        "    bulk = np.median(eigvals)\n",
        "    signal = eigvals.max()\n",
        "    return signal / (bulk + 1e-8)\n",
        "\n",
        "def spectrum_snr_per_layer(model):\n",
        "    snrs = {}\n",
        "    for name, param in model.named_parameters():\n",
        "        if \"weight\" in name and param.ndim >= 2:\n",
        "            snrs[name] = compute_snr(param)\n",
        "    return snrs\n",
        "\n",
        "# ============================================================\n",
        "# MERGING MULTI-TIPO (Aggiornato)\n",
        "# ============================================================\n",
        "def selective_merge(modelA, modelB, snrA, snrB, threshold, merge_type=\"standard\", alpha=0.5):\n",
        "    merged = get_model()\n",
        "    stateA = modelA.state_dict()\n",
        "    stateB = modelB.state_dict()\n",
        "    merged_state = merged.state_dict()\n",
        "\n",
        "    for name in merged_state:\n",
        "        if name not in snrA:\n",
        "            merged_state[name].copy_(alpha*stateA[name] + (1-alpha)*stateB[name])\n",
        "            continue\n",
        "\n",
        "        if merge_type == \"standard\":\n",
        "            merged_state[name].copy_(alpha*stateA[name] + (1-alpha)*stateB[name])\n",
        "\n",
        "        elif merge_type == \"snr_lowA\":\n",
        "            if max(snrA[name], snrB[name]) > threshold:\n",
        "                merged_state[name].copy_(alpha*stateA[name] + (1-alpha)*stateB[name])\n",
        "            else:\n",
        "                merged_state[name].copy_(stateA[name])\n",
        "\n",
        "        elif merge_type == \"snr_lowB\":\n",
        "            if max(snrA[name], snrB[name]) > threshold:\n",
        "                merged_state[name].copy_(alpha*stateA[name] + (1-alpha)*stateB[name])\n",
        "            else:\n",
        "                merged_state[name].copy_(stateB[name])\n",
        "\n",
        "        elif merge_type == \"snr_max\":\n",
        "            if max(snrA[name], snrB[name]) > threshold:\n",
        "                merged_state[name].copy_(alpha*stateA[name] + (1-alpha)*stateB[name])\n",
        "            else:\n",
        "                merged_state[name].copy_(stateA[name] if snrA[name] > snrB[name] else stateB[name])\n",
        "\n",
        "        elif merge_type == \"snr_weighted_dynamic\":\n",
        "            # Calcolo alpha dinamico basato sul rapporto SNR\n",
        "            snr_sum = snrA[name] + snrB[name] + 1e-8\n",
        "            dynamic_alpha = snrA[name] / snr_sum\n",
        "\n",
        "            if max(snrA[name], snrB[name]) > threshold:\n",
        "                # Se il segnale è alto, pesa di più il modello con SNR maggiore\n",
        "                merged_state[name].copy_(dynamic_alpha * stateA[name] + (1 - dynamic_alpha) * stateB[name])\n",
        "            else:\n",
        "                # Altrimenti media standard per stabilità\n",
        "                merged_state[name].copy_(0.5 * stateA[name] + 0.5 * stateB[name])\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown merge_type: {merge_type}\")\n",
        "\n",
        "    merged.load_state_dict(merged_state)\n",
        "    return merged\n",
        "\n",
        "# ============================================================\n",
        "# ESPERIMENTO\n",
        "# ============================================================\n",
        "loaderC_train, loaderC_test, loaderD_train, loaderD_test = get_datasets()\n",
        "\n",
        "print(\"Fine-tuning Model C (FashionMNIST)...\")\n",
        "model_C = finetune(get_model(), loaderC_train)\n",
        "\n",
        "print(\"Fine-tuning Model D (KMNIST)...\")\n",
        "model_D = finetune(get_model(), loaderD_train)\n",
        "\n",
        "print(\"Evaluating baseline models...\")\n",
        "acc_C_onC = evaluate(model_C, loaderC_test)\n",
        "acc_D_onD = evaluate(model_D, loaderD_test)\n",
        "acc_C_onD = evaluate(model_C, loaderD_test)\n",
        "acc_D_onC = evaluate(model_D, loaderC_test)\n",
        "\n",
        "print(\"Computing Spectrum SNR...\")\n",
        "snr_C = spectrum_snr_per_layer(model_C)\n",
        "snr_D = spectrum_snr_per_layer(model_D)\n",
        "\n",
        "# Aggiunto snr_weighted_dynamic alla lista dei tipi\n",
        "merge_types = [\"standard\", \"snr_lowA\", \"snr_lowB\", \"snr_max\", \"snr_weighted_dynamic\"]\n",
        "thresholds = [3.0, 5.0, 15.0, 25.0]\n",
        "results_taskC = {mtype: [] for mtype in merge_types}\n",
        "results_taskD = {mtype: [] for mtype in merge_types}\n",
        "for t in thresholds:\n",
        "    for mtype in merge_types:\n",
        "        merged = selective_merge(model_C, model_D, snr_C, snr_D, threshold=t, merge_type=mtype)\n",
        "        accC = evaluate(merged, loaderC_test)\n",
        "        accD = evaluate(merged, loaderD_test)\n",
        "        results_taskC[mtype].append(accC)\n",
        "        results_taskD[mtype].append(accD)\n",
        "        print(f\"Threshold {t:.1f} | Merge {mtype:20} | Acc C: {accC:.4f} | Acc D: {accD:.4f}\")\n",
        "\n",
        "# ============================================================\n",
        "# PLOT\n",
        "# ============================================================\n",
        "plt.figure(figsize=(15,6))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "for mtype in merge_types:\n",
        "    plt.plot(thresholds, results_taskC[mtype], marker=\"o\", label=f\"{mtype}\")\n",
        "plt.axhline(acc_C_onC, color=\"green\", linestyle=\":\", label=\"Expert C (Fashion)\")\n",
        "plt.axhline(acc_D_onC, color=\"orange\", linestyle=\":\", label=\"Non-Expert D\")\n",
        "plt.title(\"Accuracy on Task C (FashionMNIST)\")\n",
        "plt.xlabel(\"SNR Threshold\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "for mtype in merge_types:\n",
        "    plt.plot(thresholds, results_taskD[mtype], marker=\"o\", label=f\"{mtype}\")\n",
        "plt.axhline(acc_C_onD, color=\"green\", linestyle=\":\", label=\"Non-Expert C\")\n",
        "plt.axhline(acc_D_onD, color=\"orange\", linestyle=\":\", label=\"Expert D (KMNIST)\")\n",
        "plt.title(\"Accuracy on Task D (KMNIST)\")\n",
        "plt.xlabel(\"SNR Threshold\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ]
}