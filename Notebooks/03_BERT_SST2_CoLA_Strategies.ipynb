{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pHb6Rhc2WgK9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "from datasets import load_dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from copy import deepcopy\n",
        "\n",
        "# ==========================================\n",
        "# 1. SETUP MODELLI BINARI (SST-2 & CoLA)\n",
        "# ==========================================\n",
        "print(\"Caricamento modelli nativamente binari...\")\n",
        "model_id_1 = \"textattack/bert-base-uncased-SST-2\"\n",
        "model_id_2 = \"textattack/bert-base-uncased-CoLA\"\n",
        "base_id = \"bert-base-uncased\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id_1)\n",
        "model1 = AutoModelForSequenceClassification.from_pretrained(model_id_1)\n",
        "model2 = AutoModelForSequenceClassification.from_pretrained(model_id_2)\n",
        "model_base = AutoModelForSequenceClassification.from_pretrained(base_id, num_labels=2)\n",
        "\n",
        "def get_dataloader(dataset_name, config=None, split=\"validation\", size=200):\n",
        "    ds = load_dataset(dataset_name, config, split=split)\n",
        "    subset = ds.select(range(min(size, len(ds))))\n",
        "    def tokenize_fn(examples):\n",
        "        return tokenizer(examples[\"sentence\"], truncation=True, padding=\"max_length\", max_length=128)\n",
        "    return DataLoader(subset.map(tokenize_fn, batched=True).with_format(\"torch\"), batch_size=16)\n",
        "\n",
        "dl_sst2 = get_dataloader(\"glue\", \"sst2\")\n",
        "dl_cola = get_dataloader(\"glue\", \"cola\")\n",
        "\n",
        "def evaluate_dual(model):\n",
        "    model.eval()\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    def run_eval(dl):\n",
        "        correct, total = 0, 0\n",
        "        for batch in dl:\n",
        "            ids, mask, y = batch['input_ids'].to(device), batch['attention_mask'].to(device), batch['label'].to(device)\n",
        "            with torch.no_grad():\n",
        "                logits = model(ids, attention_mask=mask).logits\n",
        "                preds = torch.argmax(logits, dim=1)\n",
        "                correct += (preds == y).sum().item()\n",
        "                total += y.size(0)\n",
        "        return correct / total\n",
        "    return run_eval(dl_sst2), run_eval(dl_cola)\n",
        "\n",
        "# ==========================================\n",
        "# 2. CALCOLO SNR SPECTRUM\n",
        "# ==========================================\n",
        "def compute_snr(p):\n",
        "    W = p.detach().cpu().float().numpy()\n",
        "    if W.ndim < 2: return 0.0\n",
        "    if W.ndim > 2: W = W.reshape(W.shape[0], -1)\n",
        "    N, M = W.shape\n",
        "    Q = max(N, M) / min(N, M)\n",
        "    sigma_2 = np.var(W)\n",
        "    lambda_plus = sigma_2 * (1 + np.sqrt(1/Q))**2\n",
        "    corr = (W.T @ W) / min(N, M)\n",
        "    eigs = np.linalg.eigvalsh(corr)\n",
        "    eigs = np.maximum(eigs, 1e-9)\n",
        "    return np.sum(eigs[eigs > lambda_plus]) / (np.sum(eigs[eigs <= lambda_plus]) + 1e-9)\n",
        "\n",
        "print(\"Analisi SNR in corso...\")\n",
        "snr_m1 = {n: compute_snr(p) for n, p in model1.named_parameters() if 'layer' in n and 'weight' in n}\n",
        "snr_m2 = {n: compute_snr(p) for n, p in model2.named_parameters() if 'layer' in n and 'weight' in n}\n",
        "\n",
        "# ==========================================\n",
        "# 3. STRATEGIE DI MERGING\n",
        "# ==========================================\n",
        "def perform_merge(strategy, p_threshold):\n",
        "    merged = deepcopy(model1)\n",
        "    sd1, sd2, sdb = model1.state_dict(), model2.state_dict(), model_base.state_dict()\n",
        "    new_sd = {}\n",
        "    max_snrs = [max(snr_m1[k], snr_m2[k]) for k in snr_m1.keys()]\n",
        "    t_val = np.percentile(max_snrs, 100 - p_threshold)\n",
        "\n",
        "    for k in sd1.keys():\n",
        "        if k in snr_m1:\n",
        "            s1, s2 = snr_m1[k], snr_m2[k]\n",
        "            is_high = max(s1, s2) > t_val\n",
        "            if strategy == \"standard\":\n",
        "                new_sd[k] = 0.5 * sd1[k] + 0.5 * sd2[k]\n",
        "            elif strategy == \"spectrum_reset\":\n",
        "                new_sd[k] = (0.5 * sd1[k] + 0.5 * sd2[k]) if is_high else sdb.get(k, sd1[k])\n",
        "            elif strategy == \"snr_winner\":\n",
        "                new_sd[k] = (sd1[k] if s1 > s2 else sd2[k]) if is_high else (0.5 * sd1[k] + 0.5 * sd2[k])\n",
        "        else:\n",
        "            new_sd[k] = 0.5 * sd1[k] + 0.5 * sd2[k]\n",
        "    merged.load_state_dict(new_sd)\n",
        "    return merged\n",
        "\n",
        "# ==========================================\n",
        "# 4. ESECUZIONE ESPERIMENTO\n",
        "# ==========================================\n",
        "thresholds = [25, 50, 70]\n",
        "print(\"Valutazione Standard...\")\n",
        "res_std = evaluate_dual(perform_merge(\"standard\", 0))\n",
        "print(\"Valutazione Spectrum Reset...\")\n",
        "res_reset = [evaluate_dual(perform_merge(\"spectrum_reset\", t)) for t in thresholds]\n",
        "print(\"Valutazione SNR Winner...\")\n",
        "res_winner = [evaluate_dual(perform_merge(\"snr_winner\", t)) for t in thresholds]\n",
        "\n",
        "# ==========================================\n",
        "# 5. PLOTTING DEI RISULTATI\n",
        "# ==========================================\n",
        "x_labels = [f\"Top {t}%\" for t in thresholds]\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 7))\n",
        "\n",
        "# Plot SST-2 (Sentiment)\n",
        "ax1.axhline(y=res_std[0], color='gray', linestyle='--', label='Standard Merge (Baseline)')\n",
        "ax1.plot(x_labels, [r[0] for r in res_reset], 'o-', linewidth=2, label='Spectrum Base Reset')\n",
        "ax1.plot(x_labels, [r[0] for r in res_winner], 's-', linewidth=2, color='green', label='SNR Winner Strategy')\n",
        "ax1.set_title(\"SST-2 Accuracy (Sentiment Analysis)\", fontsize=14)\n",
        "ax1.set_ylabel(\"Accuracy Score\")\n",
        "ax1.grid(True, alpha=0.3)\n",
        "ax1.legend()\n",
        "\n",
        "# Plot CoLA (Linguistic Acceptability)\n",
        "ax2.axhline(y=res_std[1], color='gray', linestyle='--', label='Standard Merge (Baseline)')\n",
        "ax2.plot(x_labels, [r[1] for r in res_reset], 'o-', linewidth=2, label='Spectrum Base Reset')\n",
        "ax2.plot(x_labels, [r[1] for r in res_winner], 's-', linewidth=2, color='green', label='SNR Winner Strategy')\n",
        "ax2.set_title(\"CoLA Accuracy (Grammar Checker)\", fontsize=14)\n",
        "ax2.set_ylabel(\"Accuracy Score\")\n",
        "ax2.grid(True, alpha=0.3)\n",
        "ax2.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Grafico dei Picchi SNR\n",
        "plt.figure(figsize=(15, 5))\n",
        "plt.plot(list(snr_m1.values()), label='SNR SST-2', color='teal', marker='.')\n",
        "plt.plot(list(snr_m2.values()), label='SNR CoLA', color='orange', marker='.')\n",
        "plt.title(\"SNR Peaks across BERT Layers\")\n",
        "plt.xlabel(\"Layer Index (Flattened)\")\n",
        "plt.ylabel(\"Spectral SNR\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    }
  ]
}
